{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data:  699\n",
      "Training:  307\n",
      "Test:  392\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "def load_data(filename, split, training_data = [], test_data = []):\n",
    "    with open(filename, 'r') as file:\n",
    "        rows = csv.reader(file)\n",
    "        res = list(zip(*rows)) #transpose the matrix\n",
    "        #print(res)\n",
    "        data_set = list(map(list, zip(*res)))\n",
    "        #print(data_set)\n",
    "        print('Total Data: ', len(data_set))\n",
    "        \n",
    "        for x in range(len(data_set)):\n",
    "            if random.random() < split:\n",
    "                training_data.append(data_set[x])\n",
    "            else:\n",
    "                test_data.append(data_set[x])\n",
    "\n",
    "training_data = []\n",
    "test_data = []\n",
    "load_data('clean_data.csv', 0.44, training_data, test_data)\n",
    "print('Training: ', len(training_data))\n",
    "print('Test: ', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['5', '1', '1', '1', '2', '1', '3', '1', '1', '2'], ['3', '1', '1', '1', '2', '2', '3', '1', '1', '2'], ['4', '1', '1', '3', '2', '1', '3', '1', '1', '2'], ['2', '1', '1', '1', '2', '1', '2', '1', '1', '2'], ['10', '7', '7', '6', '4', '10', '4', '1', '2', '4'], ['6', '1', '1', '1', '2', '1', '3', '1', '1', '2'], ['10', '5', '5', '3', '6', '7', '7', '10', '1', '4'], ['8', '4', '5', '1', '2', '?', '7', '3', '1', '4'], ['5', '2', '3', '4', '2', '7', '3', '6', '1', '4'], ['2', '1', '1', '1', '2', '1', '3', '1', '1', '2']]\n"
     ]
    }
   ],
   "source": [
    "print(training_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"Clump Thickness\", \"Uniformity of Cell Size\", \"Uniformity of Cell Shape\",\"Marginal Adhesion\", \"Single Epithelial Cell Size\", \"Bare Nuclei\",\"Bland Chromatin\", \"Normal Nucleoli\", \"Mitoses\", \"label\"]\n",
    "def unique_vals(rows, col):\n",
    "    return set([row[col] for row in rows])\n",
    "\n",
    "def class_counts(rows):\n",
    "    counts = {}\n",
    "    for row in rows:\n",
    "        label = row[-1] #last column is our result column\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        counts[label] += 1\n",
    "    return counts\n",
    "\n",
    "def is_neumeric(value):\n",
    "    return isinstance(value, int) or isinstance(value, float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2': 203, '4': 104}\n"
     ]
    }
   ],
   "source": [
    "print(class_counts(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPartition:\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value #Not using these value, just comparing with hardcoded value: 5\n",
    "        \n",
    "    def check_condition(self, example):\n",
    "        val = example[self.column]\n",
    "        if val == \"\" or val == \"?\" or val == \"NAN\":\n",
    "            val = 0\n",
    "        val = int(val)\n",
    "        return val >= 5\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Is %s >= 5?\" % (header[self.column])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data(rows, partitioner):\n",
    "    value_5_or_more, value_less_than_5 = [], []\n",
    "    for row in rows:\n",
    "        if(partitioner.check_condition(row)):\n",
    "            value_5_or_more.append(row)\n",
    "        else:\n",
    "            value_less_than_5.append(row)\n",
    "    return value_5_or_more, value_less_than_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['5', '1', '1', '1', '2', '1', '3', '1', '1', '2'], ['3', '1', '1', '1', '2', '2', '3', '1', '1', '2'], ['4', '1', '1', '3', '2', '1', '3', '1', '1', '2']]\n",
      "Printing Less than 5 from column 0:\n",
      "[['3', '1', '1', '1', '2', '2', '3', '1', '1', '2'], ['4', '1', '1', '3', '2', '1', '3', '1', '1', '2']]\n"
     ]
    }
   ],
   "source": [
    "sample = training_data[:3]\n",
    "t, f = partition_data(sample, DataPartition(0, 5))\n",
    "print(sample)\n",
    "print(\"Printing Less than 5 from column 0:\")\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entropy(rows):\n",
    "\n",
    "    if len(rows) == 0:\n",
    "        return 0\n",
    "    counts = class_counts(rows)\n",
    "    for label in counts:\n",
    "        p = counts[label] / float(len(rows))\n",
    "        break\n",
    "        \n",
    "    if p is 0 or p is 1:\n",
    "        return 0\n",
    "    elif p is 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return -(1 * p * np.log2(p)) - ((1 - p) * np.log2((1 - p)))\n",
    "\n",
    "def gini(rows):\n",
    "    counts = class_counts(rows)\n",
    "    for label in counts:\n",
    "        p = counts[label] / float(len(rows))\n",
    "        break\n",
    "        \n",
    "    if p is 0 or p is 1:\n",
    "        return 0\n",
    "    elif p is 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2.0 * p * (1-p)\n",
    "\n",
    "def misclassification_error(rows):\n",
    "    counts = class_counts(rows)\n",
    "    for label in counts:\n",
    "        p = counts[label] / float(len(rows))\n",
    "        break\n",
    "        \n",
    "    if p is 0 or p is 1:\n",
    "        return 0\n",
    "    elif p is 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 1 - np.max([p, 1 - p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 0.9236293018025431\n",
      "Gini: 0.4480047533660835\n",
      "Misclassification Error: 0.3387622149837134\n"
     ]
    }
   ],
   "source": [
    "current_uncertainty = entropy(training_data)\n",
    "print(\"Entropy:\", current_uncertainty)\n",
    "\n",
    "current_uncertainty = gini(training_data)\n",
    "print(\"Gini:\", current_uncertainty)\n",
    "\n",
    "current_uncertainty = misclassification_error(training_data)\n",
    "print(\"Misclassification Error:\", current_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the information gain\n",
    "#InfoGain = Total Entropy(gini) - (weighted_avg * entropy_or_gini of all features)\n",
    "\n",
    "def info_gain(left, right, current_uncertainty):\n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    return current_uncertainty - p * gini(left) - (1-p) * gini(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2623370009230868\n"
     ]
    }
   ],
   "source": [
    "current_uncertainty = gini(training_data)\n",
    "true_rows, false_rows = partition_data(training_data, DataPartition(0, 5))\n",
    "ig = info_gain(true_rows, false_rows, current_uncertainty)\n",
    "print(ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(rows):\n",
    "    best_gain = 0\n",
    "    best_partition = None\n",
    "    current_uncertainty = gini(rows)\n",
    "    n_features = len(rows[0]) - 1\n",
    "    \n",
    "    for col in range(n_features):\n",
    "        partition = DataPartition(col, 5)\n",
    "        t, f = partition_data(rows, partition)\n",
    "        \n",
    "        if(len(t) == 0 or len(f) == 0):\n",
    "            continue #The entropy will be zero, thats why we dont need to calculate\n",
    "            \n",
    "        gain = info_gain(t, f, current_uncertainty)\n",
    "        if gain >= best_gain:\n",
    "            best_gain, best_partition = gain, partition\n",
    "        \n",
    "    return best_gain, best_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self, rows):\n",
    "        self.predictions = class_counts(rows)\n",
    "        \n",
    "class DecisionNode:\n",
    "    def __init__(self, partition, true_branch, false_branch):\n",
    "        self.partition = partition\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "        \n",
    "def build_tree(rows):\n",
    "    best_gain, best_partition = find_best_split(rows)\n",
    "    \n",
    "    #For base case, no further info gain, Return a Leaf\n",
    "    if best_gain == 0:\n",
    "        return Leaf(rows)\n",
    "    \n",
    "    #We have useful feature, and need to partition on that feature\n",
    "    true_rows, false_rows = partition_data(rows, best_partition)\n",
    "    \n",
    "    #Build true branch - Recursive\n",
    "    true_branch = build_tree(true_rows)\n",
    "    \n",
    "    #Build left branch - Recursive\n",
    "    false_branch = build_tree(false_rows)\n",
    "    \n",
    "    return DecisionNode(best_partition, true_branch, false_branch)\n",
    "\n",
    "def print_tree(node, spacing = \"\"):\n",
    "    if isinstance(node, Leaf):\n",
    "        print(spacing + \"Predict\", node.predictions)\n",
    "        return\n",
    "    \n",
    "    #Print the partition Node\n",
    "    print(spacing + str(node.partition))\n",
    "    \n",
    "    #Print true branch Recursively\n",
    "    print(spacing + \"--> Ture:\")\n",
    "    print_tree(node.true_branch, spacing + \"  \")\n",
    "    \n",
    "    #Print false branch Recursively\n",
    "    print(spacing + \"--> False:\")\n",
    "    print_tree(node.false_branch, spacing + \"  \")\n",
    "    \n",
    "    \n",
    "    \n",
    "def classify(row, node):\n",
    "    \n",
    "    #Base case, for Leaf\n",
    "    if isinstance(node, Leaf):\n",
    "        return node.predictions\n",
    "    \n",
    "    if node.partition.check_condition(row):\n",
    "        return classify(row, node.true_branch)\n",
    "    else:\n",
    "        return classify(row, node.false_branch)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Bare Nuclei >= 5?\n",
      "--> Ture:\n",
      "  Is Uniformity of Cell Shape >= 5?\n",
      "  --> Ture:\n",
      "    Is Bland Chromatin >= 5?\n",
      "    --> Ture:\n",
      "      Predict {'4': 47}\n",
      "    --> False:\n",
      "      Is Marginal Adhesion >= 5?\n",
      "      --> Ture:\n",
      "        Is Normal Nucleoli >= 5?\n",
      "        --> Ture:\n",
      "          Predict {'4': 5}\n",
      "        --> False:\n",
      "          Is Single Epithelial Cell Size >= 5?\n",
      "          --> Ture:\n",
      "            Predict {'2': 1}\n",
      "          --> False:\n",
      "            Predict {'4': 2}\n",
      "      --> False:\n",
      "        Predict {'4': 13}\n",
      "  --> False:\n",
      "    Is Clump Thickness >= 5?\n",
      "    --> Ture:\n",
      "      Is Bland Chromatin >= 5?\n",
      "      --> Ture:\n",
      "        Predict {'4': 12}\n",
      "      --> False:\n",
      "        Is Marginal Adhesion >= 5?\n",
      "        --> Ture:\n",
      "          Predict {'2': 1}\n",
      "        --> False:\n",
      "          Predict {'4': 3}\n",
      "    --> False:\n",
      "      Is Normal Nucleoli >= 5?\n",
      "      --> Ture:\n",
      "        Predict {'4': 1}\n",
      "      --> False:\n",
      "        Is Bland Chromatin >= 5?\n",
      "        --> Ture:\n",
      "          Predict {'2': 1}\n",
      "        --> False:\n",
      "          Predict {'4': 1, '2': 1}\n",
      "--> False:\n",
      "  Is Uniformity of Cell Size >= 5?\n",
      "  --> Ture:\n",
      "    Is Marginal Adhesion >= 5?\n",
      "    --> Ture:\n",
      "      Is Normal Nucleoli >= 5?\n",
      "      --> Ture:\n",
      "        Is Bland Chromatin >= 5?\n",
      "        --> Ture:\n",
      "          Predict {'4': 3, '2': 1}\n",
      "        --> False:\n",
      "          Predict {'4': 1}\n",
      "      --> False:\n",
      "        Predict {'4': 3}\n",
      "    --> False:\n",
      "      Predict {'4': 8}\n",
      "  --> False:\n",
      "    Is Bland Chromatin >= 5?\n",
      "    --> Ture:\n",
      "      Is Clump Thickness >= 5?\n",
      "      --> Ture:\n",
      "        Is Single Epithelial Cell Size >= 5?\n",
      "        --> Ture:\n",
      "          Predict {'4': 2}\n",
      "        --> False:\n",
      "          Is Uniformity of Cell Shape >= 5?\n",
      "          --> Ture:\n",
      "            Predict {'4': 2}\n",
      "          --> False:\n",
      "            Predict {'2': 1}\n",
      "      --> False:\n",
      "        Predict {'2': 1}\n",
      "    --> False:\n",
      "      Is Mitoses >= 5?\n",
      "      --> Ture:\n",
      "        Predict {'4': 1}\n",
      "      --> False:\n",
      "        Predict {'2': 196}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':    \n",
    "    decision_tree = build_tree(training_data)\n",
    "    print_tree(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 392\n",
      "True_Counter: 369\n",
      "Accuracy: 0.9368686868686869 TPR: 0.8848920863309353 PPV: 0.9318181818181818 TNR:  0.9649805447470817 F1 Score: 0.9077490774907748\n"
     ]
    }
   ],
   "source": [
    "def print_leaf(counts):\n",
    "    total = sum(counts.values()) * 1.0\n",
    "    probs = {}\n",
    "    for label in counts.keys():\n",
    "        probs[label] = str(int(counts[label] / total * 100)) + \"%\"\n",
    "    return probs\n",
    "\n",
    "def get_predicted(class_counts):\n",
    "    total = sum(class_counts.values()) * 1.0\n",
    "    probs = {}\n",
    "    for label in class_counts.keys():\n",
    "        probs[label] = str(int(class_counts[label] / total * 100)) + \"%\"\n",
    "        \n",
    "    if(len(probs) == 1):\n",
    "        return next(iter(probs))\n",
    "    elif(len(probs) == 2):\n",
    "        if(probs['2'] == probs['4']):\n",
    "            return '0'\n",
    "        elif(probs['2'] > probs['4']):\n",
    "            return '2'\n",
    "        elif(probs['4'] > probs['2']):\n",
    "            return '4'\n",
    "\n",
    "\n",
    "d = test_data[:]\n",
    "actual_predict = []\n",
    "total = len(d)\n",
    "true_counter = 0\n",
    "i = 1\n",
    "for row in d:\n",
    "    original = row[-1]\n",
    "    predicted = get_predicted(classify(row, decision_tree))\n",
    "    if predicted == '0':\n",
    "        predicted = original\n",
    "    #print(\"Data-\", i, \" :Original: %s - Predicted: %s\" % (original, predicted))\n",
    "    i = i +1\n",
    "    actual_predict.append([original, predicted])\n",
    "    if(original == predicted):\n",
    "        true_counter = true_counter + 1\n",
    "    \n",
    "    \n",
    "print(\"Total:\", total)\n",
    "print(\"True_Counter:\", true_counter)\n",
    "\n",
    "TN = 1\n",
    "FP = 1 \n",
    "FN = 1 \n",
    "TP = 1\n",
    "for i in range(len(actual_predict)):\n",
    "    if(actual_predict[i][0] == '2'):\n",
    "        if(actual_predict[i][1] == '2'):\n",
    "            TN += 1\n",
    "        elif(actual_predict[i][1] == '4'):\n",
    "            FP += 1\n",
    "    elif(actual_predict[i][0] == '4'):\n",
    "        if(actual_predict[i][1] == '2'):\n",
    "            FN += 1\n",
    "        elif(actual_predict[i][1] == '4'):\n",
    "            TP += 1\n",
    "        \n",
    "#print('TN: ', TN)\n",
    "#print('FP: ', FP)\n",
    "#print('FN: ', FN)\n",
    "#print('TP: ', TP)\n",
    "    \n",
    "ac = (TN + TP) / (TN+TP+FP+FN)\n",
    "#print('KNN Accuracy:', ac *100, '%')\n",
    "    \n",
    "tpr = TP / (TP+FN)\n",
    "#print('True positive rate:', tpr * 100, '%')\n",
    "    \n",
    "ppv = TP/ (TP+FP)\n",
    "#print('Positive predictve value:', ppv * 100, '%')\n",
    "    \n",
    "tnr = TN/ (TN+FP)\n",
    "#print('True negative rate:', tnr * 100, '%')\n",
    "    \n",
    "f1_score = 2 * ppv * (tpr / (ppv+tpr))\n",
    "#print('F1 Score:', f1_score * 100, '%')\n",
    "    \n",
    "print(\"Accuracy:\", ac, \"TPR:\", tpr, \"PPV:\", ppv, \"TNR: \",tnr, \"F1 Score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>2</th>\n",
       "      <th>1.3</th>\n",
       "      <th>3</th>\n",
       "      <th>1.4</th>\n",
       "      <th>1.5</th>\n",
       "      <th>2.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     5   1  1.1  1.2  2  1.3   3  1.4  1.5  2.1\n",
       "693  3   1    1    1  3    2   1    1    1    2\n",
       "694  2   1    1    1  2    1   1    1    1    2\n",
       "695  5  10   10    3  7    3   8   10    2    4\n",
       "696  4   8    6    4  3    4  10    6    1    4\n",
       "697  4   8    8    5  4    5  10    4    1    4"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "global headers\n",
    "\n",
    "df = pd.read_csv('clean_data_2.csv')\n",
    "df.dropna(how=\"all\", inplace=True) # drops the empty line at file-end\n",
    "df.replace('?', '0')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X = df.ix[:,0:7].values\n",
    "y = df.ix[:,7].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#X_std = StandardScaler().fit_transform(X)\n",
    "X_std = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix \n",
      "[[ 7.93928338  5.55089968  5.48739584  3.91742959  3.25915405  6.05177737\n",
      "   3.83992387]\n",
      " [ 5.55089968  9.31821601  8.2292428   6.15106494  5.08334943  7.6085557\n",
      "   5.62971885]\n",
      " [ 5.48739584  8.2292428   8.83793622  5.79915356  4.73886447  7.62603133\n",
      "   5.3393915 ]\n",
      " [ 3.91742959  6.15106494  5.79915356  8.16019741  3.79334684  6.92412838\n",
      "   4.64749869]\n",
      " [ 3.25915405  5.08334943  4.73886447  3.79334684  4.90803402  4.70159053\n",
      "   3.33050774]\n",
      " [ 6.05177737  7.6085557   7.62603133  6.92412838  4.70159053 13.26505326\n",
      "   5.96855537]\n",
      " [ 3.83992387  5.62971885  5.3393915   4.64749869  3.33050774  5.96855537\n",
      "   5.95387518]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "mean_vec = np.mean(X_std, axis=0)\n",
    "cov_mat = (X_std - mean_vec).T.dot((X_std - mean_vec)) / (X_std.shape[0]-1)\n",
    "print('Covariance matrix \\n%s' %cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy covariance matrix: \n",
      "[[ 7.93928338  5.55089968  5.48739584  3.91742959  3.25915405  6.05177737\n",
      "   3.83992387]\n",
      " [ 5.55089968  9.31821601  8.2292428   6.15106494  5.08334943  7.6085557\n",
      "   5.62971885]\n",
      " [ 5.48739584  8.2292428   8.83793622  5.79915356  4.73886447  7.62603133\n",
      "   5.3393915 ]\n",
      " [ 3.91742959  6.15106494  5.79915356  8.16019741  3.79334684  6.92412838\n",
      "   4.64749869]\n",
      " [ 3.25915405  5.08334943  4.73886447  3.79334684  4.90803402  4.70159053\n",
      "   3.33050774]\n",
      " [ 6.05177737  7.6085557   7.62603133  6.92412838  4.70159053 13.26505326\n",
      "   5.96855537]\n",
      " [ 3.83992387  5.62971885  5.3393915   4.64749869  3.33050774  5.96855537\n",
      "   5.95387518]]\n"
     ]
    }
   ],
   "source": [
    "print('NumPy covariance matrix: \\n%s' %np.cov(X_std.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvectors \n",
      "[[-0.32378205  0.27305161  0.7938543  -0.00580964  0.4278504   0.08031767\n",
      "  -0.02937177]\n",
      " [-0.43282524  0.36131418 -0.15975298 -0.73307983 -0.22364769 -0.26239067\n",
      "  -0.01789311]\n",
      " [-0.42014151  0.30334874 -0.07612944  0.66285625 -0.27691292 -0.45732305\n",
      "  -0.02148068]\n",
      " [-0.35745458 -0.16522228 -0.49159833  0.04210934  0.75223335 -0.0859212\n",
      "  -0.1680721 ]\n",
      " [-0.26574258  0.22150235 -0.16044883  0.11482192 -0.21611403  0.73850877\n",
      "  -0.49928871]\n",
      " [-0.48468967 -0.79071592  0.22310023 -0.05609528 -0.27866164 -0.02454944\n",
      "  -0.09310682]\n",
      " [-0.31303614  0.03579201 -0.14591839  0.07125901 -0.00569086  0.40271021\n",
      "   0.84388944]]\n",
      "\n",
      "Eigenvalues \n",
      "[42.25162489  4.63250512  4.20633512  0.80670423  2.73476541  1.74034155\n",
      "  2.01031915]\n"
     ]
    }
   ],
   "source": [
    "cov_mat = np.cov(X_std.T)\n",
    "\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "print('Eigenvectors \\n%s' %eig_vecs)\n",
    "print('\\nEigenvalues \\n%s' %eig_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvectors \n",
      "[[-3.34174683e-01  8.58621208e-01  1.82953642e-03 -9.02804234e-02\n",
      "  -2.36532386e-01  2.77910126e-01 -9.87997593e-02]\n",
      " [-4.15339418e-01 -2.79907633e-02  7.40201859e-01  2.48394914e-01\n",
      "   4.15977898e-01  8.51364652e-02  1.91898490e-01]\n",
      " [-4.11925081e-01  3.33429610e-02 -6.61444891e-01  1.91111179e-01\n",
      "   5.68507380e-01  1.52988255e-02  1.78152892e-01]\n",
      " [-3.63994788e-01 -4.52951101e-01 -4.63019047e-02 -3.60097608e-01\n",
      "  -9.52623217e-02  6.59077124e-01 -2.95078594e-01]\n",
      " [-3.63170195e-01 -1.70546171e-01 -6.84435048e-02  6.71384414e-01\n",
      "  -4.26946519e-01 -1.97778239e-01 -4.02716162e-01]\n",
      " [-3.70492475e-01 -5.58945872e-04  7.05995084e-02 -5.30264820e-01\n",
      "   1.29363147e-01 -6.42633631e-01 -3.83219437e-01]\n",
      " [-3.80116701e-01 -1.63166715e-01 -5.26863121e-02 -1.78935273e-01\n",
      "  -4.89613228e-01 -1.69725719e-01  7.24959519e-01]]\n",
      "\n",
      "Eigenvalues \n",
      "[4.99625079 0.53742575 0.08911138 0.46680163 0.26252505 0.31170571\n",
      " 0.33617968]\n"
     ]
    }
   ],
   "source": [
    "cor_mat1 = np.corrcoef(X_std.T)\n",
    "\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat1)\n",
    "\n",
    "print('Eigenvectors \\n%s' %eig_vecs)\n",
    "print('\\nEigenvalues \\n%s' %eig_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvectors \n",
      "[[-3.34174683e-01  8.58621208e-01  1.82953642e-03 -9.02804234e-02\n",
      "  -2.36532386e-01  2.77910126e-01 -9.87997593e-02]\n",
      " [-4.15339418e-01 -2.79907633e-02  7.40201859e-01  2.48394914e-01\n",
      "   4.15977898e-01  8.51364652e-02  1.91898490e-01]\n",
      " [-4.11925081e-01  3.33429610e-02 -6.61444891e-01  1.91111179e-01\n",
      "   5.68507380e-01  1.52988255e-02  1.78152892e-01]\n",
      " [-3.63994788e-01 -4.52951101e-01 -4.63019047e-02 -3.60097608e-01\n",
      "  -9.52623217e-02  6.59077124e-01 -2.95078594e-01]\n",
      " [-3.63170195e-01 -1.70546171e-01 -6.84435048e-02  6.71384414e-01\n",
      "  -4.26946519e-01 -1.97778239e-01 -4.02716162e-01]\n",
      " [-3.70492475e-01 -5.58945872e-04  7.05995084e-02 -5.30264820e-01\n",
      "   1.29363147e-01 -6.42633631e-01 -3.83219437e-01]\n",
      " [-3.80116701e-01 -1.63166715e-01 -5.26863121e-02 -1.78935273e-01\n",
      "  -4.89613228e-01 -1.69725719e-01  7.24959519e-01]]\n",
      "\n",
      "Eigenvalues \n",
      "[4.99625079 0.53742575 0.08911138 0.46680163 0.26252505 0.31170571\n",
      " 0.33617968]\n"
     ]
    }
   ],
   "source": [
    "cor_mat2 = np.corrcoef(X.T)\n",
    "\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat2)\n",
    "\n",
    "print('Eigenvectors \\n%s' %eig_vecs)\n",
    "print('\\nEigenvalues \\n%s' %eig_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[292.1186472854618, 61.38950277071731, 55.507820072796584, 45.32050775549522, 39.385951692411446, 37.30246833126855, 23.983974043180158]\n",
      "[0, 1, 2, 3, 4, 5, 6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u,s,v = np.linalg.svd(X_std.T)\n",
    "s\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "k_array = []\n",
    "cost_array = []\n",
    "# Train k-Means with k values in [2,10] and calculate WSSSE for each clustering\n",
    "for k in range(0,len(s)):\n",
    "    cost_array.append(s[k])\n",
    "    k_array.append(k)\n",
    "print(cost_array)\n",
    "print(k_array)\n",
    "plt.scatter(k_array, cost_array, c = 'blue')\n",
    "plt.title(\"Cost Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues in descending order:\n",
      "4.996250793262668\n",
      "0.5374257495649637\n",
      "0.466801631174978\n",
      "0.3361796834781113\n",
      "0.31170571498893546\n",
      "0.2625250463856567\n",
      "0.08911138114468903\n"
     ]
    }
   ],
   "source": [
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort()\n",
    "eig_pairs.reverse()\n",
    "\n",
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "print('Eigenvalues in descending order:')\n",
    "for i in eig_pairs:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix W:\n",
      " [[-3.34174683e-01  8.58621208e-01]\n",
      " [-4.15339418e-01 -2.79907633e-02]\n",
      " [-4.11925081e-01  3.33429610e-02]\n",
      " [-3.63994788e-01 -4.52951101e-01]\n",
      " [-3.63170195e-01 -1.70546171e-01]\n",
      " [-3.70492475e-01 -5.58945872e-04]\n",
      " [-3.80116701e-01 -1.63166715e-01]]\n"
     ]
    }
   ],
   "source": [
    "matrix_w = np.hstack((eig_pairs[0][1].reshape(7,1), \n",
    "                      eig_pairs[1][1].reshape(7,1)))\n",
    "\n",
    "print('Matrix W:\\n', matrix_w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
